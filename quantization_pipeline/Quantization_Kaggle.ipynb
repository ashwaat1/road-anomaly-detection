{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:12:38.907940Z",
     "iopub.status.busy": "2026-02-20T15:12:38.907147Z",
     "iopub.status.idle": "2026-02-20T15:12:47.068037Z",
     "shell.execute_reply": "2026-02-20T15:12:47.067070Z",
     "shell.execute_reply.started": "2026-02-20T15:12:38.907904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics onnx onnxruntime onnxruntime-tools opencv-python numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:12:58.506720Z",
     "iopub.status.busy": "2026-02-20T15:12:58.506335Z",
     "iopub.status.idle": "2026-02-20T15:12:58.741761Z",
     "shell.execute_reply": "2026-02-20T15:12:58.740760Z",
     "shell.execute_reply.started": "2026-02-20T15:12:58.506687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cp /kaggle/input/models/rambhattaee22b047/best3/pytorch/default/1/best3.pt /kaggle/working/best3.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T14:39:03.175941Z",
     "iopub.status.busy": "2026-02-20T14:39:03.175329Z",
     "iopub.status.idle": "2026-02-20T14:39:13.503865Z",
     "shell.execute_reply": "2026-02-20T14:39:13.502307Z",
     "shell.execute_reply.started": "2026-02-20T14:39:03.175895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!yolo export model=best3.pt format=onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T14:40:33.343750Z",
     "iopub.status.busy": "2026-02-20T14:40:33.343349Z",
     "iopub.status.idle": "2026-02-20T14:40:36.817055Z",
     "shell.execute_reply": "2026-02-20T14:40:36.815842Z",
     "shell.execute_reply.started": "2026-02-20T14:40:33.343695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python -m onnxruntime.quantization.preprocess --input best3.onnx --output pre2.onnx --skip_symbolic_shape TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-20T14:41:01.871504Z",
     "iopub.status.busy": "2026-02-20T14:41:01.870775Z",
     "iopub.status.idle": "2026-02-20T14:43:15.281792Z",
     "shell.execute_reply": "2026-02-20T14:43:15.280253Z",
     "shell.execute_reply.started": "2026-02-20T14:41:01.871458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import shutil # <--- ADD THIS IMPORT\n",
    "from onnxruntime.quantization import QuantFormat, QuantType, quantize_static, CalibrationDataReader, CalibrationMethod\n",
    "\n",
    "# ... [KEEP YOUR YOLODataReader AND benchmark FUNCTIONS EXACTLY THE SAME] ...\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. YOLO DATA READER ---\n",
    "def _preprocess_images(images_folder: str, height: int, width: int):\n",
    "    \"\"\"Loads and preprocesses images strictly for YOLO (RGB, 0-1 norm, CHW).\"\"\"\n",
    "    valid_extensions = {\".jpg\", \".jpeg\", \".png\"}\n",
    "    image_names = [f for f in os.listdir(images_folder) if any(f.lower().endswith(ext) for ext in valid_extensions)]\n",
    "    \n",
    "    unconcatenated_batch_data = []\n",
    "\n",
    "    for image_name in image_names:\n",
    "        image_filepath = os.path.join(images_folder, image_name)\n",
    "        img = cv2.imread(image_filepath)\n",
    "        if img is None: continue\n",
    "        \n",
    "        # Exact YOLO Preprocessing for 640p\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        nchw_data = np.transpose(img, (2, 0, 1)) \n",
    "        \n",
    "        unconcatenated_batch_data.append(nchw_data)\n",
    "\n",
    "    return unconcatenated_batch_data\n",
    "\n",
    "\n",
    "# --- 1. MEMORY-SAFE LAZY DATA READER ---\n",
    "class YOLODataReader(CalibrationDataReader):\n",
    "    def __init__(self, calibration_image_folder: str, model_path: str):\n",
    "        self.image_folder = calibration_image_folder\n",
    "        valid_extensions = {\".jpg\", \".jpeg\", \".png\"}\n",
    "        \n",
    "        # Store only the filenames in RAM, not the actual images!\n",
    "        self.image_names = [\n",
    "            f for f in os.listdir(calibration_image_folder) \n",
    "            if any(f.lower().endswith(ext) for ext in valid_extensions)\n",
    "        ]\n",
    "        self.iterator = iter(self.image_names)\n",
    "\n",
    "        # Dynamically read the 640x640 shape\n",
    "        session = onnxruntime.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
    "        shape = session.get_inputs()[0].shape\n",
    "        self.height, self.width = shape[2], shape[3]\n",
    "        self.input_name = session.get_inputs()[0].name\n",
    "\n",
    "    def get_next(self):\n",
    "        # ONNX calls this to get images ONE AT A TIME\n",
    "        try:\n",
    "            image_name = next(self.iterator)\n",
    "        except StopIteration:\n",
    "            return None # Calibration is done\n",
    "\n",
    "        image_filepath = os.path.join(self.image_folder, image_name)\n",
    "        img = cv2.imread(image_filepath)\n",
    "        \n",
    "        # Failsafe for corrupted files\n",
    "        if img is None:\n",
    "            return self.get_next() \n",
    "            \n",
    "        # YOLO Preprocessing \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (self.width, self.height))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        nchw_data = np.transpose(img, (2, 0, 1)) \n",
    "        \n",
    "        return {self.input_name: np.expand_dims(nchw_data, axis=0)}\n",
    "\n",
    "    def rewind(self):\n",
    "        # Resets the iterator\n",
    "        self.iterator = iter(self.image_names)\n",
    "\n",
    "# --- 2. BENCHMARK TOOL ---\n",
    "def benchmark(model_path):\n",
    "    opts = onnxruntime.SessionOptions()\n",
    "    opts.intra_op_num_threads = 4  # Simulate quad-core\n",
    "    \n",
    "    session = onnxruntime.InferenceSession(model_path, sess_opts=opts, providers=['CPUExecutionProvider'])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    shape = session.get_inputs()[0].shape\n",
    "    batch = shape[0] if isinstance(shape[0], int) else 1\n",
    "    \n",
    "    total = 0.0\n",
    "    runs = 15 \n",
    "    input_data = np.zeros((batch, shape[1], shape[2], shape[3]), np.float32)\n",
    "    \n",
    "    print(f\"Benchmarking shape: {input_data.shape}\")\n",
    "    \n",
    "    for _ in range(3): # Warmup\n",
    "        _ = session.run([], {input_name: input_data})\n",
    "        \n",
    "    for i in range(runs):\n",
    "        start = time.perf_counter()\n",
    "        _ = session.run([], {input_name: input_data})\n",
    "        end = (time.perf_counter() - start) * 1000\n",
    "        total += end\n",
    "    \n",
    "    total /= runs\n",
    "    print(f\"Avg Latency: {total:.2f} ms | Est. FPS: {1000/total:.2f}\\n\")\n",
    "\n",
    "# --- 3. MAIN EXECUTION ---\n",
    "def main():\n",
    "    # 1. Define Paths\n",
    "    read_only_model = \"/kaggle/input/models/rambhattaee22b047/pre-onnx/onnx/default/1/pre.onnx\"\n",
    "    writable_model = \"/kaggle/working/pre2.onnx\"\n",
    "    output_int8_model = \"/kaggle/working/int8_best3.onnx\"\n",
    "    calibration_dir = \"/kaggle/input/datasets/rambhattaee22b047/calibration2\"\n",
    "    \n",
    "    # 2. Copy the model to a writable directory so ONNX can create its temporary files\n",
    "    print(f\"Copying model to writable directory: {writable_model}\")\n",
    "    shutil.copy2(read_only_model, writable_model)\n",
    "\n",
    "    print(\"Initializing YOLO Data Reader...\")\n",
    "    # Update to use the writable model\n",
    "    dr = YOLODataReader(calibration_dir, writable_model)\n",
    "\n",
    "    print(\"Starting high-accuracy static quantization (QDQ S8S8 + Entropy + Per-Channel)...\")\n",
    "    \n",
    "    cpu_extra_options = {\n",
    "        \"ActivationSymmetric\": False, \n",
    "        \"WeightSymmetric\": True,\n",
    "        \"CalibMaxIntermediateOutputs\": 10\n",
    "    }\n",
    "    \n",
    "    nodes_to_exclude = [\n",
    "        '/model.23/Concat_1',\n",
    "        '/model.23/Sigmoid',\n",
    "        '/model.23/Concat_3',\n",
    "        '/model.23/Concat_6',\n",
    "        '/model.23/Split',\n",
    "        '/model.23/ReduceMax',\n",
    "        '/model.23/TopK',\n",
    "        '/model.23/GatherElements',\n",
    "        '/model.23/Gather_3',\n",
    "    ]\n",
    "    \n",
    "    # 3. Run Quantization on the writable model\n",
    "    quantize_static(\n",
    "        model_input=writable_model,\n",
    "        model_output=output_int8_model,\n",
    "        calibration_data_reader=dr,\n",
    "        quant_format=QuantFormat.QDQ,        \n",
    "        weight_type=QuantType.QInt8,         \n",
    "        activation_type=QuantType.QUInt8,     \n",
    "        per_channel=True,                    \n",
    "        calibrate_method=CalibrationMethod.Entropy, \n",
    "        extra_options=cpu_extra_options,\n",
    "        nodes_to_exclude=nodes_to_exclude\n",
    "    )\n",
    "    \n",
    "    print(\"Quantization complete!\\n\")\n",
    "\n",
    "    print(\"--- BENCHMARK: FP32 MODEL ---\")\n",
    "    benchmark(writable_model)\n",
    "\n",
    "    print(\"--- BENCHMARK: INT8 MODEL ---\")\n",
    "    benchmark(output_int8_model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T14:43:39.628168Z",
     "iopub.status.busy": "2026-02-20T14:43:39.627235Z",
     "iopub.status.idle": "2026-02-20T14:43:45.508936Z",
     "shell.execute_reply": "2026-02-20T14:43:45.507946Z",
     "shell.execute_reply.started": "2026-02-20T14:43:39.628128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from IPython.display import FileLink\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INT8_MODEL_PATH = '/kaggle/working/int8_best3.onnx'\n",
    "TEST_IMG_DIR = '/kaggle/input/datasets/rambhattaee22b047/calibration2'\n",
    "\n",
    "# We set the exact output directory where we want the images\n",
    "# We will force Ultralytics to NOT create subfolders like 'predict'\n",
    "OUTPUT_DIR = '/kaggle/working/int8_ultralytics_results'\n",
    "\n",
    "# 1. Load the INT8 Model\n",
    "print(f\"[*] Loading model: {INT8_MODEL_PATH}\")\n",
    "model = YOLO(INT8_MODEL_PATH, task='detect')\n",
    "\n",
    "# Clean up any old runs so we don't zip old data\n",
    "if os.path.exists(OUTPUT_DIR): \n",
    "    shutil.rmtree(OUTPUT_DIR)\n",
    "\n",
    "image_files = sorted(glob(os.path.join(TEST_IMG_DIR, \"*.jpg\")))[:50]\n",
    "\n",
    "print(\"[*] Running INT8 via Ultralytics engine (CPU)...\")\n",
    "for img_path in tqdm(image_files):\n",
    "    model.predict(\n",
    "        source=img_path,\n",
    "        conf=0.1, \n",
    "        device='cpu',\n",
    "        save=True,\n",
    "        # This combination forces it to save directly to OUTPUT_DIR without making 'predict' subfolders\n",
    "        project=OUTPUT_DIR, \n",
    "        name='', \n",
    "        exist_ok=True,\n",
    "        verbose=False # Keeps the notebook output clean\n",
    "    )\n",
    "\n",
    "# 3. Zip & Download\n",
    "print(f\"[*] Zipping results from {OUTPUT_DIR}...\")\n",
    "# shutil.make_archive(base_name, format, root_dir)\n",
    "zip_path = shutil.make_archive('/kaggle/working/int8_ultralytics_results', 'zip', OUTPUT_DIR)\n",
    "print(f\"âœ… Created zip at: {zip_path}\")\n",
    "\n",
    "# Display download link\n",
    "FileLink(r'int8_ultralytics_results.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15764560,
     "datasetId": 9533621,
     "sourceId": 14899918,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 15759003,
     "datasetId": 9530063,
     "sourceId": 14894789,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 15765338,
     "modelId": 590296,
     "modelInstanceId": 577965,
     "sourceId": 756709,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 15764395,
     "modelId": 590223,
     "modelInstanceId": 577892,
     "sourceId": 756621,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31287,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
